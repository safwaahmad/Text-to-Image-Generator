{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**Text to Image generator using Ngrok and streamlit in Google Colab**"
      ],
      "metadata": {
        "id": "PmbyN91jXGWY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pyngrok\n"
      ],
      "metadata": {
        "id": "8x_smOSxjO8y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ngrok authtoken token\n",
        "\n"
      ],
      "metadata": {
        "id": "g_Zv8B7SjqiX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install diffusers torch torchvision streamlit  numpy huggingface-hub\n"
      ],
      "metadata": {
        "id": "WwxXMBfCj27N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyngrok import ngrok\n"
      ],
      "metadata": {
        "id": "VRW0GAMijTzq"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile app01.py\n",
        "import streamlit as st\n",
        "from diffusers import DiffusionPipeline\n",
        "import torch\n",
        "from PIL import Image\n",
        "import io\n",
        "import numpy as np\n",
        "import time\n",
        "\n",
        "@st.cache_resource\n",
        "def load_model():\n",
        "    model = DiffusionPipeline.from_pretrained(\"runwayml/stable-diffusion-v1-5\")\n",
        "    model.to(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    return model\n",
        "\n",
        "generator = load_model()\n",
        "\n",
        "st.title('Text to Image Generator')\n",
        "prompt = st.text_input(\"Enter your prompt:\", \"A scenic landscape painting\")\n",
        "\n",
        "if st.button('Generate Image'):\n",
        "    start_time = time.time()  # Start timing\n",
        "    with st.spinner('Generating image...'):\n",
        "        # Generate the image with a low number of inference steps\n",
        "        output = generator(prompt, num_inference_steps=5, eta=0.0)  # Adjust ETA to possibly reduce computation\n",
        "        image = output.images[0]\n",
        "\n",
        "        # Convert to NumPy array\n",
        "        image = np.array(image)\n",
        "\n",
        "        # Convert to PIL Image\n",
        "        pil_image = Image.fromarray(image.astype(np.uint8))  # Cast to uint8 for PIL compatibility\n",
        "\n",
        "        # Display the image\n",
        "        st.image(pil_image, caption='Generated Image', use_column_width=True)\n",
        "\n",
        "        # Provide a download button\n",
        "        buf = io.BytesIO()\n",
        "        pil_image.save(buf, format=\"JPEG\")\n",
        "        byte_im = buf.getvalue()\n",
        "        st.download_button(\n",
        "            label=\"Download Image\",\n",
        "            data=byte_im,\n",
        "            file_name=\"generated_image.jpg\",\n",
        "            mime=\"image/jpeg\"\n",
        "        )\n",
        "\n",
        "    # Record and display time taken\n",
        "    end_time = time.time()\n",
        "    st.write(f\"Time taken to generate image: {end_time - start_time:.2f} seconds\")\n",
        "\n",
        "st.write(\"Enter a textual prompt and press generate to create an image.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G6ExQsnSlMQm",
        "outputId": "9ce4af66-1772-451f-fa27-28e57e44e8d6"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing app01.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!streamlit run app_1.py &>/dev/null&\n"
      ],
      "metadata": {
        "id": "id3wKcltp0ae"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Start an HTTP tunnel on the default port 8501 for Streamlit\n",
        "url = ngrok.connect(8501)\n",
        "print(\"Access your Streamlit app at:\", url)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-2godZDtp1Po",
        "outputId": "aaa1c0af-ef38-44ad-8fd1-13c03bff7b44"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Access your Streamlit app at: NgrokTunnel: \"https://ee42-34-106-16-150.ngrok-free.app\" -> \"http://localhost:8501\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "active_tunnels = ngrok.get_tunnels()\n",
        "print(active_tunnels)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a6EQvCKEp53W",
        "outputId": "9aba803f-5776-496f-f8b6-dde2f8a2386d"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[<NgrokTunnel: \"https://ee42-34-106-16-150.ngrok-free.app\" -> \"http://localhost:8501\">]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "0NMWTvIkrYt8"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
